{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d880610b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee4bf0b5",
   "metadata": {},
   "source": [
    "Load necessary modules to environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d98b28c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import machine_learning_new as ml\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13cc2967",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = (\n",
    "    r'DRIVER={SQL Server};'\n",
    "    r'SERVER=lct-sqlbidev\\dev;'\n",
    "    r'DATABASE=Informatics_SSAS_Live;'\n",
    "    r'Trusted_Connection=yes;'\n",
    "    )\n",
    "\n",
    "cnxn = pyodbc.connect(conn_str) # connect using the connection string\n",
    "\n",
    "cursor_source = cnxn.cursor()\n",
    "\n",
    "cursor_source.execute(\"EXEC [Informatics_SSAS_Live].[Reporting].\"\n",
    "               \"[usp_ML_Inpatient_Readmissions_process]\") # the sql we want to run\n",
    "\n",
    "source_data = cursor_source.fetchall() # return all the data\n",
    "\n",
    "\n",
    "# get list of headers using list comprehension - this will account for new \n",
    "# columns dynamically as they are added to the SQL source data\n",
    "source_headers = [column[0] for column in cursor_source.description] \n",
    "\n",
    "#headers\n",
    "\n",
    "# load data into pandas dataframe\n",
    "source_df = pd.DataFrame(np.array(source_data),\n",
    "                                columns = source_headers)\n",
    "\n",
    "# source_df['ReAdmission'] = source_df['ReAdmission'].astype(int)\n",
    "\n",
    "#source_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24dfc7",
   "metadata": {},
   "source": [
    "Truncate categorical data to make results easier to read and handle DQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bb2e1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converted 'ReAdmission' to numeric\n",
      "[INFO] Converted 'DeprivationIndex' to numeric\n",
      "[INFO] Converted 'Age' to numeric\n",
      "[INFO] Converted 'AgeGroup' to category\n",
      "[INFO] Converted 'LearningDisability' to numeric\n",
      "[INFO] Converted 'AutismDiagnosis' to numeric\n",
      "[INFO] Converted 'ExBAF' to numeric\n",
      "[INFO] Converted 'ethnicity_clean' to category\n",
      "[INFO] Converted 'gender_clean' to category\n",
      "[INFO] Converted 'accom_clean' to category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\Departmental Shares\\IM&T\\Information\\Business Intelligence\\Heath McDonald\\HSMA\\Machine Learning\\LSCFT_ML_App\\code\\machine_learning_new.py:106: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  converted = pd.to_datetime(df[col], errors='raise')\n",
      "s:\\Departmental Shares\\IM&T\\Information\\Business Intelligence\\Heath McDonald\\HSMA\\Machine Learning\\LSCFT_ML_App\\code\\machine_learning_new.py:106: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  converted = pd.to_datetime(df[col], errors='raise')\n",
      "s:\\Departmental Shares\\IM&T\\Information\\Business Intelligence\\Heath McDonald\\HSMA\\Machine Learning\\LSCFT_ML_App\\code\\machine_learning_new.py:106: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  converted = pd.to_datetime(df[col], errors='raise')\n",
      "s:\\Departmental Shares\\IM&T\\Information\\Business Intelligence\\Heath McDonald\\HSMA\\Machine Learning\\LSCFT_ML_App\\code\\machine_learning_new.py:106: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  converted = pd.to_datetime(df[col], errors='raise')\n",
      "s:\\Departmental Shares\\IM&T\\Information\\Business Intelligence\\Heath McDonald\\HSMA\\Machine Learning\\LSCFT_ML_App\\code\\machine_learning_new.py:106: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  converted = pd.to_datetime(df[col], errors='raise')\n",
      "s:\\Departmental Shares\\IM&T\\Information\\Business Intelligence\\Heath McDonald\\HSMA\\Machine Learning\\LSCFT_ML_App\\code\\machine_learning_new.py:106: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  converted = pd.to_datetime(df[col], errors='raise')\n",
      "s:\\Departmental Shares\\IM&T\\Information\\Business Intelligence\\Heath McDonald\\HSMA\\Machine Learning\\LSCFT_ML_App\\code\\machine_learning_new.py:106: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  converted = pd.to_datetime(df[col], errors='raise')\n",
      "s:\\Departmental Shares\\IM&T\\Information\\Business Intelligence\\Heath McDonald\\HSMA\\Machine Learning\\LSCFT_ML_App\\code\\machine_learning_new.py:106: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  converted = pd.to_datetime(df[col], errors='raise')\n",
      "s:\\Departmental Shares\\IM&T\\Information\\Business Intelligence\\Heath McDonald\\HSMA\\Machine Learning\\LSCFT_ML_App\\code\\machine_learning_new.py:106: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  converted = pd.to_datetime(df[col], errors='raise')\n",
      "s:\\Departmental Shares\\IM&T\\Information\\Business Intelligence\\Heath McDonald\\HSMA\\Machine Learning\\LSCFT_ML_App\\code\\machine_learning_new.py:106: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  converted = pd.to_datetime(df[col], errors='raise')\n"
     ]
    }
   ],
   "source": [
    "if 'Ethnicity' in source_df.columns:\n",
    "\n",
    "    conditions_ethnicity = [\n",
    "        source_df['Ethnicity'] == 'Not Known/Specified',\n",
    "        source_df['Ethnicity'] == 'Not stated',\n",
    "        source_df['Ethnicity'] == 'White - British',\n",
    "        source_df['Ethnicity'] == 'White and Black African',\n",
    "        source_df['Ethnicity'] == 'Any other Asian background',\n",
    "        source_df['Ethnicity'] == 'White and Asian',\n",
    "        source_df['Ethnicity'] == 'Pakistani',\n",
    "        source_df['Ethnicity'] == 'Indian',\n",
    "        source_df['Ethnicity'] == 'Bangladeshi',\n",
    "        source_df['Ethnicity'] == 'Any other White background',\n",
    "        source_df['Ethnicity'] == 'Any other mixed background',\n",
    "        source_df['Ethnicity'] == 'Chinese',\n",
    "        source_df['Ethnicity'] == 'Any other ethnic group',\n",
    "        source_df['Ethnicity'] == 'White - Irish',\n",
    "        source_df['Ethnicity'] == 'Black or Black British - Caribbean',\n",
    "        source_df['Ethnicity'] == 'White and Black Caribbean',\n",
    "        source_df['Ethnicity'] == 'Any other Black background',\n",
    "        source_df['Ethnicity'] == 'Black or Black British - African'\n",
    "    ]       \n",
    "\n",
    "    outputs = [\n",
    "        'Not Known', 'NotStated', 'WhiteBr', 'WhiteBlkAfr', 'AsianOther',\n",
    "        'WhiteAsian', 'Pakistani', 'Indian', 'Bangladeshi',\n",
    "        'OtherWhite','OtherMixed','Chinese','AnyOther',\n",
    "        'WhiteIrish','Caribbean','WhtBlkCarib','BlackOther','BlkAfrican' \n",
    "\n",
    "    ]\n",
    "    # add new column \n",
    "    source_df['ethnicity_clean'] = np.select(conditions_ethnicity, outputs, 'Err')\n",
    "    # get rid of old column\n",
    "    source_df.drop('Ethnicity',axis=1,inplace=True)\n",
    "\n",
    "if 'Gender' in source_df.columns:\n",
    "\n",
    "    conditions_gender = [\n",
    "        source_df['Gender'] == 'Male',\n",
    "        source_df['Gender'] == 'Female',\n",
    "        source_df['Gender'] == 'Not Known',\n",
    "        source_df['Gender'] == 'Not Specified'\n",
    "    ]       \n",
    "\n",
    "    outputs_gender = [\n",
    "        'Male', 'Female', 'NK', 'NK'\n",
    "    ]\n",
    "    # add new column \n",
    "    source_df['gender_clean'] = np.select(conditions_gender, outputs_gender\n",
    "                                                , 'Err')\n",
    "    # get rid of old column\n",
    "    source_df.drop('Gender',axis=1,inplace=True)\n",
    "\n",
    "if 'AccommodationStatus' in source_df.columns:\n",
    "\n",
    "    conditions_accom = [\n",
    "        source_df['AccommodationStatus'] == 'Owner occupier',\n",
    "        source_df['AccommodationStatus'] == 'Unknown',\n",
    "        source_df['AccommodationStatus'] == 'Not known',\n",
    "        source_df['AccommodationStatus'] == 'Tenant - private landlord',\n",
    "        source_df['AccommodationStatus'] == 'Mainstream Housing',\n",
    "        source_df['AccommodationStatus'] == 'Tenant - Housing Association',\n",
    "        source_df['AccommodationStatus'] == 'Accommodation with mental health care support',\n",
    "        source_df['AccommodationStatus'] == 'Secure psychiatric unit',\n",
    "        source_df['AccommodationStatus'] == 'Independent hospital/clinic',\n",
    "        source_df['AccommodationStatus'] == 'Sheltered housing for older persons',\n",
    "        source_df['AccommodationStatus'] == 'Other accommodation with mental health care and support',\n",
    "        source_df['AccommodationStatus'] == 'Homeless',\n",
    "        source_df['AccommodationStatus'] == 'Settled mainstream housing with family/friends',\n",
    "        source_df['AccommodationStatus'] == 'NHS acute psychiatric ward',\n",
    "        source_df['AccommodationStatus'] == 'Specialist rehabilitation/recovery',\n",
    "        source_df['AccommodationStatus'] == 'Supported accommodation',\n",
    "        source_df['AccommodationStatus'] == 'Non-Mental Health Registered Care Home',\n",
    "        source_df['AccommodationStatus'] == 'Mental Health Registered Care Home',\n",
    "        source_df['AccommodationStatus'] == '[NOVALUE]',\n",
    "        source_df['AccommodationStatus'] == 'Staying with friends/family as a short term guest',\n",
    "        source_df['AccommodationStatus'] == 'Rough sleeper',\n",
    "        source_df['AccommodationStatus'] == 'Tenant - Local Authority/Arms Length Management Organisation/Registered Landlord',\n",
    "        source_df['AccommodationStatus'] == 'Other NHS facilities/hospital'\n",
    "    ]       \n",
    "\n",
    "    outputs_accom = [\n",
    "        'Owner', 'NK', 'NK', 'Private','Mainstream','HA','Supp','Psych','Hosp',\n",
    "        'Shelt','Supp','HL','FF','Psych','Rehab','Supp','CH','CH','NK','FF'\n",
    "        ,'HL','HA','NHS']\n",
    "    # add new column \n",
    "    source_df['accom_clean'] = np.select(conditions_accom, outputs_accom\n",
    "                                                , 'Oth')\n",
    "    # get rid of old column\n",
    "    source_df.drop('AccommodationStatus',axis=1,inplace=True)\n",
    "\n",
    "source_df.to_csv('check_source_data.csv', index=False)\n",
    "\n",
    "# cols_to_convert_int = ['ReAdmission', 'LearningDisability', 'AutismDiagnosis','ExBAF']\n",
    "# source_df[cols_to_convert_int] = source_df[cols_to_convert_int].astype('int64')\n",
    "\n",
    "#print(source_df.dtypes)\n",
    "\n",
    "# make sure data is of correct data types\n",
    "source_df = ml.fix_dtypes(source_df)\n",
    "\n",
    "#print(source_df.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f858f",
   "metadata": {},
   "source": [
    "split data into X and y values and scale numerical values or one hot encode categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57a9ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AgeGroup', 'ethnicity_clean', 'gender_clean', 'accom_clean']\n",
      "['DeprivationIndex', 'Age']\n",
      "      DeprivationIndex       Age  LearningDisability  AutismDiagnosis  ExBAF  \\\n",
      "0            -0.312570  1.438527                   0                0      0   \n",
      "1            -0.312570 -0.132619                   0                0      0   \n",
      "2            -0.035443  1.068846                   0                0      0   \n",
      "3            -0.035443  1.115056                   0                0      0   \n",
      "4            -0.243288 -0.640931                   0                0      0   \n",
      "...                ...       ...                 ...              ...    ...   \n",
      "8635          6.407770 -1.518924                   0                0      0   \n",
      "8636          6.407770 -1.149243                   0                0      0   \n",
      "8637          6.407770 -1.149243                   0                0      0   \n",
      "8638          6.407770 -0.502300                   0                0      0   \n",
      "8639          6.407770 -0.502300                   0                0      0   \n",
      "\n",
      "      Age_18 - 65  Age_Less Than 18  Age_Over 65  Age_Missing  eth_AnyOther  \\\n",
      "0               0                 0            1            0             0   \n",
      "1               1                 0            0            0             0   \n",
      "2               0                 0            1            0             1   \n",
      "3               0                 0            1            0             0   \n",
      "4               1                 0            0            0             0   \n",
      "...           ...               ...          ...          ...           ...   \n",
      "8635            1                 0            0            0             0   \n",
      "8636            1                 0            0            0             0   \n",
      "8637            1                 0            0            0             0   \n",
      "8638            1                 0            0            0             0   \n",
      "8639            1                 0            0            0             0   \n",
      "\n",
      "      ...  acc_NHS  acc_NK  acc_Oth  acc_Owner  acc_Private  acc_Psych  \\\n",
      "0     ...        0       1        0          0            0          0   \n",
      "1     ...        0       1        0          0            0          0   \n",
      "2     ...        0       0        0          1            0          0   \n",
      "3     ...        0       1        0          0            0          0   \n",
      "4     ...        0       1        0          0            0          0   \n",
      "...   ...      ...     ...      ...        ...          ...        ...   \n",
      "8635  ...        0       0        0          0            0          0   \n",
      "8636  ...        0       1        0          0            0          0   \n",
      "8637  ...        0       1        0          0            0          0   \n",
      "8638  ...        0       0        0          0            0          0   \n",
      "8639  ...        0       0        0          0            0          0   \n",
      "\n",
      "      acc_Rehab  acc_Shelt  acc_Supp  acc_Missing  \n",
      "0             0          0         0            0  \n",
      "1             0          0         0            0  \n",
      "2             0          0         0            0  \n",
      "3             0          0         0            0  \n",
      "4             0          0         0            0  \n",
      "...         ...        ...       ...          ...  \n",
      "8635          0          0         0            0  \n",
      "8636          0          0         0            0  \n",
      "8637          0          0         0            0  \n",
      "8638          0          0         0            0  \n",
      "8639          0          0         0            0  \n",
      "\n",
      "[8640 rows x 48 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcdonaldh\\AppData\\Local\\Temp\\3\\ipykernel_6100\\1841321918.py:23: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(X[col]):\n"
     ]
    }
   ],
   "source": [
    "target_column = \"ReAdmission\" # what we're interested in predicting\n",
    "\n",
    "# Separate features and target\n",
    "X = source_df.drop(target_column, axis=1)\n",
    "y = source_df[target_column]\n",
    "\n",
    "# Detect column types\n",
    "categorical_cols = X.select_dtypes(include=['string','object','category']).columns.tolist()\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64', 'uint8']).columns\n",
    "\n",
    "# Identify one-hot encoded columns\n",
    "one_hot_cols = [col for col in numeric_cols if ml.is_one_hot_column(X[col])]\n",
    "\n",
    "# Now exclude them from numerical preprocessing\n",
    "numerical_cols = [col for col in numeric_cols if col not in one_hot_cols]\n",
    "\n",
    "print(categorical_cols)\n",
    "print(numerical_cols)\n",
    "\n",
    "# Fill missing values \n",
    "for col in categorical_cols:\n",
    "    if pd.api.types.is_categorical_dtype(X[col]):\n",
    "        if 'Missing' not in X[col].cat.categories:\n",
    "            X[col] = X[col].cat.add_categories('Missing')\n",
    "    X[col] = X[col].fillna('Missing')\n",
    "\n",
    "X[numerical_cols] = X[numerical_cols].fillna(0)\n",
    "\n",
    "prefixes = {col: col[:3] for col in categorical_cols}\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "X = pd.get_dummies(X, columns=categorical_cols, prefix=(prefixes), dtype=int)\n",
    "\n",
    "# Scale numeric columns\n",
    "scaler = StandardScaler()\n",
    "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "print(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9344e126",
   "metadata": {},
   "source": [
    "put the data through Logistic regression model and report accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b056b805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predicting training data = 0.9788773148148148\n",
      "Accuracy of predicting test data = 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "model = ml.LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict training and test labels, and calculate accuracy\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "accuracy_train = np.mean(y_pred_train == y_train)\n",
    "accuracy_test = np.mean(y_pred_test == y_test)\n",
    "\n",
    "print (f'Accuracy of predicting training data = {accuracy_train}')\n",
    "print (f'Accuracy of predicting test data = {accuracy_test}')\n",
    "\n",
    "# Examine feature weights and sort by most influential\n",
    "co_eff = model.coef_[0]\n",
    "\n",
    "co_eff_df = pd.DataFrame()\n",
    "co_eff_df['feature'] = list(X)\n",
    "co_eff_df['co_eff'] = co_eff\n",
    "co_eff_df['abs_co_eff'] = np.abs(co_eff)\n",
    "co_eff_df.sort_values(by='abs_co_eff', ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34376365",
   "metadata": {},
   "source": [
    "plot top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "366e2614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "co_eff_df.head(10).plot(kind='barh', x='feature', y='co_eff', legend=False)\n",
    "plt.title(\"Top 10 Influential Features\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12345e0",
   "metadata": {},
   "source": [
    "Use machine learning to run the data through many models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f527af48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mcdonaldh\\AppData\\Local\\anaconda3\\envs\\hsma_project\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 139, number of negative: 6773\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 74\n",
      "[LightGBM] [Info] Number of data points in the train set: 6912, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020110 -> initscore=-3.886225\n",
      "[LightGBM] [Info] Start training from score -3.886225\n",
      "                       Model  Training_accuracy  Test_accuracy  Precision  \\\n",
      "0    Decision Tree - Depth:1           0.979890       0.977431   0.977431   \n",
      "1    Random Forest - Depth:1           0.979890       0.977431   0.977431   \n",
      "2         XG Boost - Depth:1           0.979890       0.977431   0.977431   \n",
      "3    Decision Tree - Depth:2           0.979890       0.977431   0.977431   \n",
      "4    Random Forest - Depth:2           0.979890       0.977431   0.977431   \n",
      "5         XG Boost - Depth:2           0.979890       0.977431   0.977431   \n",
      "6    Decision Tree - Depth:3           0.979890       0.977431   0.977431   \n",
      "7    Random Forest - Depth:3           0.979890       0.977431   0.977431   \n",
      "8         XG Boost - Depth:3           0.979890       0.977431   0.977431   \n",
      "9    Decision Tree - Depth:4           0.979890       0.977431   0.977431   \n",
      "10   Random Forest - Depth:4           0.979890       0.977431   0.977431   \n",
      "11        XG Boost - Depth:4           0.979890       0.977431   0.977431   \n",
      "12   Decision Tree - Depth:5           0.979890       0.977431   0.977431   \n",
      "13   Random Forest - Depth:5           0.979890       0.977431   0.977431   \n",
      "14        XG Boost - Depth:5           0.979890       0.977431   0.977431   \n",
      "15   Decision Tree - Depth:6           0.980035       0.976852   0.976852   \n",
      "16   Random Forest - Depth:6           0.979890       0.977431   0.977431   \n",
      "17        XG Boost - Depth:6           0.979890       0.977431   0.977431   \n",
      "18   Decision Tree - Depth:7           0.980035       0.976852   0.976852   \n",
      "19   Random Forest - Depth:7           0.979890       0.977431   0.977431   \n",
      "20        XG Boost - Depth:7           0.979890       0.977431   0.977431   \n",
      "21   Decision Tree - Depth:8           0.980035       0.976852   0.976852   \n",
      "22   Random Forest - Depth:8           0.979890       0.977431   0.977431   \n",
      "23        XG Boost - Depth:8           0.979890       0.977431   0.977431   \n",
      "24   Decision Tree - Depth:9           0.980035       0.976852   0.976852   \n",
      "25   Random Forest - Depth:9           0.979890       0.977431   0.977431   \n",
      "26        XG Boost - Depth:9           0.979890       0.977431   0.977431   \n",
      "27       Logistic Regression           0.979890       0.977431   0.977431   \n",
      "28                 ADA Boost           0.979890       0.977431   0.977431   \n",
      "29                 Cat Boost           0.980035       0.976852   0.976852   \n",
      "30      Light Gradient Boost           0.979890       0.977431   0.977431   \n",
      "31  Histogram Gradient Boost           0.979890       0.977431   0.977431   \n",
      "32    Support Vector Machine           0.979890       0.977431   0.977431   \n",
      "33               Naive Bayes           0.099103       0.096644   0.096644   \n",
      "\n",
      "      Recall  Specificity  F1 Score  Training MAE  Testing MAE  Training MSE  \\\n",
      "0   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "1   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "2   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "3   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "4   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "5   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "6   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "7   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "8   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "9   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "10  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "11  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "12  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "13  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "14  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "15  0.976852     0.977417  0.976852      0.019965     0.023148      0.019965   \n",
      "16  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "17  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "18  0.976852     0.977417  0.976852      0.019965     0.023148      0.019965   \n",
      "19  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "20  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "21  0.976852     0.977417  0.976852      0.019965     0.023148      0.019965   \n",
      "22  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "23  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "24  0.976852     0.977417  0.976852      0.019965     0.023148      0.019965   \n",
      "25  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "26  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "27  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "28  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "29  0.976852     0.977417  0.976852      0.019965     0.023148      0.019965   \n",
      "30  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "31  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "32  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
      "33  0.096644     1.000000  0.096644      0.900897     0.903356      0.900897   \n",
      "\n",
      "    Test MSE  Training RMSE  Test RMSE  Training R2    Test R2  \n",
      "0   0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "1   0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "2   0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "3   0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "4   0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "5   0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "6   0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "7   0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "8   0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "9   0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "10  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "11  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "12  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "13  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "14  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "15  0.023148       0.141299   0.152145    -0.013181  -0.049324  \n",
      "16  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "17  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "18  0.023148       0.141299   0.152145    -0.013181  -0.049324  \n",
      "19  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "20  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "21  0.023148       0.141299   0.152145    -0.013181  -0.049324  \n",
      "22  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "23  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "24  0.023148       0.141299   0.152145    -0.013181  -0.049324  \n",
      "25  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "26  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "27  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "28  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "29  0.023148       0.141299   0.152145    -0.013181  -0.049324  \n",
      "30  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "31  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "32  0.022569       0.141810   0.150231    -0.020523  -0.023091  \n",
      "33  0.903356       0.949156   0.950451   -44.717947 -39.949857  \n"
     ]
    }
   ],
   "source": [
    "# 2. Run all models\n",
    "results_df = ml.run_all_models(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 3. View results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53e5a99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training_accuracy</th>\n",
       "      <th>Test_accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training MAE</th>\n",
       "      <th>Testing MAE</th>\n",
       "      <th>Training MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Training RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Training R Squared</th>\n",
       "      <th>Test R Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree - Depth:1</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest - Depth:1</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XG Boost - Depth:1</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree - Depth:2</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest - Depth:2</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XG Boost - Depth:2</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree - Depth:3</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest - Depth:3</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XG Boost - Depth:3</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree - Depth:4</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest - Depth:4</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XG Boost - Depth:4</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Decision Tree - Depth:5</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest - Depth:5</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XG Boost - Depth:5</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree - Depth:6</td>\n",
       "      <td>0.980035</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.977417</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.141299</td>\n",
       "      <td>0.152145</td>\n",
       "      <td>-0.013181</td>\n",
       "      <td>-0.049324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest - Depth:6</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XG Boost - Depth:6</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Decision Tree - Depth:7</td>\n",
       "      <td>0.980035</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.977417</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.141299</td>\n",
       "      <td>0.152145</td>\n",
       "      <td>-0.013181</td>\n",
       "      <td>-0.049324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random Forest - Depth:7</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XG Boost - Depth:7</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Decision Tree - Depth:8</td>\n",
       "      <td>0.980035</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.977417</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.141299</td>\n",
       "      <td>0.152145</td>\n",
       "      <td>-0.013181</td>\n",
       "      <td>-0.049324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random Forest - Depth:8</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XG Boost - Depth:8</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Decision Tree - Depth:9</td>\n",
       "      <td>0.980035</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.977417</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.141299</td>\n",
       "      <td>0.152145</td>\n",
       "      <td>-0.013181</td>\n",
       "      <td>-0.049324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Random Forest - Depth:9</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XG Boost - Depth:9</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ADA Boost</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cat Boost</td>\n",
       "      <td>0.980035</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.977417</td>\n",
       "      <td>0.976852</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.141299</td>\n",
       "      <td>0.152145</td>\n",
       "      <td>-0.013181</td>\n",
       "      <td>-0.049324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Light Gradient Boost</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Histogram Gradient Boost</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.979890</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.977431</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.141810</td>\n",
       "      <td>0.150231</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.099103</td>\n",
       "      <td>0.096644</td>\n",
       "      <td>0.096644</td>\n",
       "      <td>0.096644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096644</td>\n",
       "      <td>0.900897</td>\n",
       "      <td>0.903356</td>\n",
       "      <td>0.900897</td>\n",
       "      <td>0.903356</td>\n",
       "      <td>0.949156</td>\n",
       "      <td>0.950451</td>\n",
       "      <td>-44.717947</td>\n",
       "      <td>-39.949857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Training_accuracy  Test_accuracy  Precision  \\\n",
       "0    Decision Tree - Depth:1           0.979890       0.977431   0.977431   \n",
       "1    Random Forest - Depth:1           0.979890       0.977431   0.977431   \n",
       "2         XG Boost - Depth:1           0.979890       0.977431   0.977431   \n",
       "3    Decision Tree - Depth:2           0.979890       0.977431   0.977431   \n",
       "4    Random Forest - Depth:2           0.979890       0.977431   0.977431   \n",
       "5         XG Boost - Depth:2           0.979890       0.977431   0.977431   \n",
       "6    Decision Tree - Depth:3           0.979890       0.977431   0.977431   \n",
       "7    Random Forest - Depth:3           0.979890       0.977431   0.977431   \n",
       "8         XG Boost - Depth:3           0.979890       0.977431   0.977431   \n",
       "9    Decision Tree - Depth:4           0.979890       0.977431   0.977431   \n",
       "10   Random Forest - Depth:4           0.979890       0.977431   0.977431   \n",
       "11        XG Boost - Depth:4           0.979890       0.977431   0.977431   \n",
       "12   Decision Tree - Depth:5           0.979890       0.977431   0.977431   \n",
       "13   Random Forest - Depth:5           0.979890       0.977431   0.977431   \n",
       "14        XG Boost - Depth:5           0.979890       0.977431   0.977431   \n",
       "15   Decision Tree - Depth:6           0.980035       0.976852   0.976852   \n",
       "16   Random Forest - Depth:6           0.979890       0.977431   0.977431   \n",
       "17        XG Boost - Depth:6           0.979890       0.977431   0.977431   \n",
       "18   Decision Tree - Depth:7           0.980035       0.976852   0.976852   \n",
       "19   Random Forest - Depth:7           0.979890       0.977431   0.977431   \n",
       "20        XG Boost - Depth:7           0.979890       0.977431   0.977431   \n",
       "21   Decision Tree - Depth:8           0.980035       0.976852   0.976852   \n",
       "22   Random Forest - Depth:8           0.979890       0.977431   0.977431   \n",
       "23        XG Boost - Depth:8           0.979890       0.977431   0.977431   \n",
       "24   Decision Tree - Depth:9           0.980035       0.976852   0.976852   \n",
       "25   Random Forest - Depth:9           0.979890       0.977431   0.977431   \n",
       "26        XG Boost - Depth:9           0.979890       0.977431   0.977431   \n",
       "27       Logistic Regression           0.979890       0.977431   0.977431   \n",
       "28                 ADA Boost           0.979890       0.977431   0.977431   \n",
       "29                 Cat Boost           0.980035       0.976852   0.976852   \n",
       "30      Light Gradient Boost           0.979890       0.977431   0.977431   \n",
       "31  Histogram Gradient Boost           0.979890       0.977431   0.977431   \n",
       "32    Support Vector Machine           0.979890       0.977431   0.977431   \n",
       "33               Naive Bayes           0.099103       0.096644   0.096644   \n",
       "\n",
       "      Recall  Specificity  F1 Score  Training MAE  Testing MAE  Training MSE  \\\n",
       "0   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "1   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "2   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "3   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "4   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "5   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "6   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "7   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "8   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "9   0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "10  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "11  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "12  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "13  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "14  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "15  0.976852     0.977417  0.976852      0.019965     0.023148      0.019965   \n",
       "16  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "17  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "18  0.976852     0.977417  0.976852      0.019965     0.023148      0.019965   \n",
       "19  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "20  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "21  0.976852     0.977417  0.976852      0.019965     0.023148      0.019965   \n",
       "22  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "23  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "24  0.976852     0.977417  0.976852      0.019965     0.023148      0.019965   \n",
       "25  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "26  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "27  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "28  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "29  0.976852     0.977417  0.976852      0.019965     0.023148      0.019965   \n",
       "30  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "31  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "32  0.977431     0.977431  0.977431      0.020110     0.022569      0.020110   \n",
       "33  0.096644     1.000000  0.096644      0.900897     0.903356      0.900897   \n",
       "\n",
       "    Test MSE  Training RMSE  Test RMSE  Training R Squared  Test R Squared  \n",
       "0   0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "1   0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "2   0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "3   0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "4   0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "5   0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "6   0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "7   0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "8   0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "9   0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "10  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "11  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "12  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "13  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "14  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "15  0.023148       0.141299   0.152145           -0.013181       -0.049324  \n",
       "16  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "17  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "18  0.023148       0.141299   0.152145           -0.013181       -0.049324  \n",
       "19  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "20  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "21  0.023148       0.141299   0.152145           -0.013181       -0.049324  \n",
       "22  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "23  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "24  0.023148       0.141299   0.152145           -0.013181       -0.049324  \n",
       "25  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "26  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "27  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "28  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "29  0.023148       0.141299   0.152145           -0.013181       -0.049324  \n",
       "30  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "31  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "32  0.022569       0.141810   0.150231           -0.020523       -0.023091  \n",
       "33  0.903356       0.949156   0.950451          -44.717947      -39.949857  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results_df)\n",
    "\n",
    "#Label columns\n",
    "results_df.columns = ['Model', 'Training_accuracy', 'Test_accuracy', 'Precision',\n",
    "                      'Recall', 'Specificity', 'F1 Score', 'Training MAE',\n",
    "                      'Testing MAE', 'Training MSE', 'Test MSE', 'Training RMSE',\n",
    "                      'Test RMSE', 'Training R Squared', 'Test R Squared']\n",
    "\n",
    "# # Save to CSV\n",
    "results_df.to_csv('results_many_models.csv', index=False)\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsma_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
